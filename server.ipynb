{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CIFAR10 Federated Mobilenet Server Side\n",
    "This code is the server part of CIFAR10 federated mobilenet for **multi** client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rounds = 2\n",
    "local_epoch = 1\n",
    "users = 24 # number of clients\n",
    "root_path = './data'\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pytorch layer modules for *Conv2D* Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 64),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "mobile_net = Model()\n",
    "mobile_net.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clientsoclist = [0]*users\n",
    "start_time = 0\n",
    "weight_count = 0\n",
    "global_weights = copy.deepcopy(mobile_net.state_dict())\n",
    "datasetsize = [0]*users\n",
    "weights_list = [0]*users\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comunication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_sendsize_list = []\n",
    "total_receivesize_list = []\n",
    "\n",
    "client_sendsize_list = [[] for i in range(users)]\n",
    "client_receivesize_list = [[] for i in range(users)]\n",
    "\n",
    "train_sendsize_list = [] \n",
    "train_receivesize_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Socket initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg, msglen\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def average_weights(w, datasize):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, data in enumerate(datasize):\n",
    "        for key in w[i].keys():\n",
    "            w[i][key] *= (data)\n",
    "    \n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    \n",
    "    \n",
    "\n",
    "# when client use only one kinds of device\n",
    "\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], (sum(datasize)))\n",
    "\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Thread define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Receive users before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_thread(func, num_user):\n",
    "    global clientsoclist\n",
    "    global start_time\n",
    "    \n",
    "    thrs = []\n",
    "    for i in range(num_user):\n",
    "        conn, addr = s.accept()\n",
    "        print('Conntected with client', int(addr[0][11:13])-10)\n",
    "        # append client socket on list\n",
    "        clientsoclist[i] = conn\n",
    "        args = (i, num_user, conn)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        thrs.append(thread)\n",
    "        thread.start()\n",
    "    print(\"Conntected with all clients Successfully!\")\n",
    "    print('-' * 60)\n",
    "    start_time = time.time()    # store start time\n",
    "    for thread in thrs:\n",
    "        thread.join()\n",
    "    end_time = time.time()  # store end time\n",
    "    print('-' * 60)\n",
    "    print(\"TrainingTime: {:.2f} sec\".format(end_time - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def receive(userid, num_users, conn): #thread for receive clients\n",
    "    global weight_count\n",
    "    \n",
    "    global datasetsize\n",
    "\n",
    "\n",
    "    msg = {\n",
    "        'rounds': rounds,\n",
    "        'client_id': userid,\n",
    "        'local_epoch': local_epoch\n",
    "    }\n",
    "\n",
    "    datasize = send_msg(conn, msg)    #send epoch\n",
    "    total_sendsize_list.append(datasize)\n",
    "    client_sendsize_list[userid].append(datasize)\n",
    "\n",
    "    train_dataset_size, datasize = recv_msg(conn)    # get total_batch of train dataset\n",
    "    total_receivesize_list.append(datasize)\n",
    "    client_receivesize_list[userid].append(datasize)\n",
    "    \n",
    "    \n",
    "    with lock:\n",
    "        datasetsize[userid] = train_dataset_size\n",
    "        weight_count += 1\n",
    "    \n",
    "    train(userid, train_dataset_size, num_users, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(userid, train_dataset_size, num_users, client_conn):\n",
    "    global weights_list\n",
    "    global global_weights\n",
    "    global weight_count\n",
    "    global mobile_net\n",
    "    global val_acc\n",
    "    \n",
    "    for r in range(rounds):\n",
    "        with lock:\n",
    "            if weight_count == num_users:\n",
    "                for i, conn in enumerate(clientsoclist):\n",
    "                    datasize = send_msg(conn, global_weights)\n",
    "                    total_sendsize_list.append(datasize)\n",
    "                    client_sendsize_list[i].append(datasize)\n",
    "                    train_sendsize_list.append(datasize)\n",
    "                    weight_count = 0\n",
    "\n",
    "        client_weights, datasize = recv_msg(client_conn)\n",
    "        total_receivesize_list.append(datasize)\n",
    "        client_receivesize_list[userid].append(datasize)\n",
    "        train_receivesize_list.append(datasize)\n",
    "\n",
    "        weights_list[userid] = client_weights\n",
    "        if userid == 1:\n",
    "            print(\"Round \" + str(r + 1) +  \" is done\")\n",
    "        with lock:\n",
    "            weight_count += 1\n",
    "            if weight_count == num_users:\n",
    "                #average\n",
    "                global_weights = average_weights(weights_list, datasetsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "host = '192.168.1.104'\n",
    "port = 2000\n",
    "s = socket.socket()\n",
    "s.bind((host, port))\n",
    "s.listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Open the server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conntected with client 1\n",
      "Conntected with client 2\n",
      "Conntected with client 4\n",
      "Conntected with client 3\n",
      "Conntected with client 5\n",
      "Conntected with client 6\n",
      "Conntected with client 7\n",
      "Conntected with client 8\n",
      "Conntected with client 9\n",
      "Conntected with client 10\n",
      "Conntected with client 11\n",
      "Conntected with client 12\n",
      "Conntected with client 13\n",
      "Conntected with client 14\n",
      "Conntected with client 15\n",
      "Conntected with client 16\n",
      "Conntected with client 17\n",
      "Conntected with client 18\n",
      "Conntected with client 19\n",
      "Conntected with client 20\n",
      "Conntected with client 21\n",
      "Conntected with client 22\n",
      "Conntected with client 23\n",
      "Conntected with client 24\n",
      "Conntected with all clients Successfully!\n",
      "------------------------------------------------------------\n",
      "Round 1 is done\n",
      "Round 2 is done\n",
      "------------------------------------------------------------\n",
      "TrainingTime: 42.64 sec\n"
     ]
    }
   ],
   "source": [
    "run_thread(receive, users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Print all of communication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---total_sendsize_list---\n",
      "total_sendsize size: 28114824 bytes\n",
      "number of total_send:  72\n",
      "\n",
      "\n",
      "---total_receivesize_list---\n",
      "total receive sizes: 28111496 bytes\n",
      "number of total receive:  72\n",
      "\n",
      "\n",
      "---client_sendsize_list(client1)---\n",
      "total client_sendsizes(client1): 1171451 bytes\n",
      "number of client_send(clientr1):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client1)---\n",
      "total client_receive sizes(client1): 1171349 bytes\n",
      "number of client_send(client1):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client2)---\n",
      "total client_sendsizes(client2): 1171451 bytes\n",
      "number of client_send(clientr2):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client2)---\n",
      "total client_receive sizes(client2): 1171349 bytes\n",
      "number of client_send(client2):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client3)---\n",
      "total client_sendsizes(client3): 1171451 bytes\n",
      "number of client_send(clientr3):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client3)---\n",
      "total client_receive sizes(client3): 1171309 bytes\n",
      "number of client_send(client3):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client4)---\n",
      "total client_sendsizes(client4): 1171451 bytes\n",
      "number of client_send(clientr4):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client4)---\n",
      "total client_receive sizes(client4): 1171309 bytes\n",
      "number of client_send(client4):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client5)---\n",
      "total client_sendsizes(client5): 1171451 bytes\n",
      "number of client_send(clientr5):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client5)---\n",
      "total client_receive sizes(client5): 1171309 bytes\n",
      "number of client_send(client5):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client6)---\n",
      "total client_sendsizes(client6): 1171451 bytes\n",
      "number of client_send(clientr6):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client6)---\n",
      "total client_receive sizes(client6): 1171309 bytes\n",
      "number of client_send(client6):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client7)---\n",
      "total client_sendsizes(client7): 1171451 bytes\n",
      "number of client_send(clientr7):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client7)---\n",
      "total client_receive sizes(client7): 1171309 bytes\n",
      "number of client_send(client7):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client8)---\n",
      "total client_sendsizes(client8): 1171451 bytes\n",
      "number of client_send(clientr8):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client8)---\n",
      "total client_receive sizes(client8): 1171309 bytes\n",
      "number of client_send(client8):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client9)---\n",
      "total client_sendsizes(client9): 1171451 bytes\n",
      "number of client_send(clientr9):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client9)---\n",
      "total client_receive sizes(client9): 1171309 bytes\n",
      "number of client_send(client9):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client10)---\n",
      "total client_sendsizes(client10): 1171451 bytes\n",
      "number of client_send(clientr10):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client10)---\n",
      "total client_receive sizes(client10): 1171309 bytes\n",
      "number of client_send(client10):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client11)---\n",
      "total client_sendsizes(client11): 1171451 bytes\n",
      "number of client_send(clientr11):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client11)---\n",
      "total client_receive sizes(client11): 1171309 bytes\n",
      "number of client_send(client11):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client12)---\n",
      "total client_sendsizes(client12): 1171451 bytes\n",
      "number of client_send(clientr12):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client12)---\n",
      "total client_receive sizes(client12): 1171309 bytes\n",
      "number of client_send(client12):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client13)---\n",
      "total client_sendsizes(client13): 1171451 bytes\n",
      "number of client_send(clientr13):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client13)---\n",
      "total client_receive sizes(client13): 1171309 bytes\n",
      "number of client_send(client13):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client14)---\n",
      "total client_sendsizes(client14): 1171451 bytes\n",
      "number of client_send(clientr14):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client14)---\n",
      "total client_receive sizes(client14): 1171309 bytes\n",
      "number of client_send(client14):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client15)---\n",
      "total client_sendsizes(client15): 1171451 bytes\n",
      "number of client_send(clientr15):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client15)---\n",
      "total client_receive sizes(client15): 1171309 bytes\n",
      "number of client_send(client15):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client16)---\n",
      "total client_sendsizes(client16): 1171451 bytes\n",
      "number of client_send(clientr16):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client16)---\n",
      "total client_receive sizes(client16): 1171309 bytes\n",
      "number of client_send(client16):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client17)---\n",
      "total client_sendsizes(client17): 1171451 bytes\n",
      "number of client_send(clientr17):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client17)---\n",
      "total client_receive sizes(client17): 1171309 bytes\n",
      "number of client_send(client17):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client18)---\n",
      "total client_sendsizes(client18): 1171451 bytes\n",
      "number of client_send(clientr18):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client18)---\n",
      "total client_receive sizes(client18): 1171309 bytes\n",
      "number of client_send(client18):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client19)---\n",
      "total client_sendsizes(client19): 1171451 bytes\n",
      "number of client_send(clientr19):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client19)---\n",
      "total client_receive sizes(client19): 1171309 bytes\n",
      "number of client_send(client19):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client20)---\n",
      "total client_sendsizes(client20): 1171451 bytes\n",
      "number of client_send(clientr20):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client20)---\n",
      "total client_receive sizes(client20): 1171309 bytes\n",
      "number of client_send(client20):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client21)---\n",
      "total client_sendsizes(client21): 1171451 bytes\n",
      "number of client_send(clientr21):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client21)---\n",
      "total client_receive sizes(client21): 1171309 bytes\n",
      "number of client_send(client21):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client22)---\n",
      "total client_sendsizes(client22): 1171451 bytes\n",
      "number of client_send(clientr22):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client22)---\n",
      "total client_receive sizes(client22): 1171309 bytes\n",
      "number of client_send(client22):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client23)---\n",
      "total client_sendsizes(client23): 1171451 bytes\n",
      "number of client_send(clientr23):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client23)---\n",
      "total client_receive sizes(client23): 1171309 bytes\n",
      "number of client_send(client23):  3\n",
      "\n",
      "\n",
      "---client_sendsize_list(client24)---\n",
      "total client_sendsizes(client24): 1171451 bytes\n",
      "number of client_send(clientr24):  3\n",
      "\n",
      "\n",
      "---client_receivesize_list(client24)---\n",
      "total client_receive sizes(client24): 1171309 bytes\n",
      "number of client_send(client24):  3\n",
      "\n",
      "\n",
      "---train_sendsize_list---\n",
      "total train_sendsizes: 28113456 bytes\n",
      "number of train_send:  48\n",
      "\n",
      "\n",
      "---train_receivesize_list---\n",
      "total train_receivesizes: 28111136 bytes\n",
      "number of train_receive:  48\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def commmunication_overhead():  \n",
    "print('\\n')\n",
    "print('---total_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in total_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total_sendsize size: {} bytes\".format(total_size))\n",
    "print(\"number of total_send: \", len(total_sendsize_list))\n",
    "print('\\n')\n",
    "\n",
    "print('---total_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in total_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total receive sizes: {} bytes\".format(total_size) )\n",
    "print(\"number of total receive: \", len(total_receivesize_list) )\n",
    "print('\\n')\n",
    "\n",
    "for i in range(users):\n",
    "    print('---client_sendsize_list(client{})---'.format(i + 1))\n",
    "    total_size = 0\n",
    "    for size in client_sendsize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_sendsizes(client{}): {} bytes\".format(i + 1, total_size))\n",
    "    print(\"number of client_send(clientr{}): \".format(i + 1), len(client_sendsize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "    print('---client_receivesize_list(client{})---'.format(i + 1))\n",
    "    total_size = 0\n",
    "    for size in client_receivesize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_receive sizes(client{}): {} bytes\".format(i + 1, total_size))\n",
    "    print(\"number of client_send(client{}): \".format(i + 1), len(client_receivesize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "print('---train_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in train_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_sendsizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_send: \", len(train_sendsize_list) )\n",
    "print('\\n')\n",
    "\n",
    "print('---train_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in train_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_receivesizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_receive: \", len(train_receivesize_list) )\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Making Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]) # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10 (root=root_path, train=True, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10 (root=root_path, train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `DataLoader` for batch generating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Number of total batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "train_total_batch = len(trainloader)\n",
    "print(train_total_batch)\n",
    "test_batch = len(testloader)\n",
    "print(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mobile_net.load_state_dict(global_weights)\n",
    "mobile_net.eval()\n",
    "mobile_net = mobile_net.to(device)\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = optim.SGD(mobile_net.parameters(), lr=lr, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Accuracy of train and each of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 25.93%, train_loss: 2.0628\n",
      "test_acc: 26.30%, test_loss: 2.0538\n",
      "Accuracy of plane : 46 %\n",
      "Accuracy of   car :  6 %\n",
      "Accuracy of  bird :  0 %\n",
      "Accuracy of   cat :  1 %\n",
      "Accuracy of  deer :  1 %\n",
      "Accuracy of   dog : 31 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 16 %\n",
      "Accuracy of  ship : 43 %\n",
      "Accuracy of truck : 57 %\n",
      "WorkingTime: 110.61 sec\n"
     ]
    }
   ],
   "source": [
    "# train acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    train_loss = 0.0\n",
    "    for j, trn in enumerate(trainloader):\n",
    "        trn_x, trn_label = trn\n",
    "        trn_x = trn_x.to(device)\n",
    "        trn_label = trn_label.clone().detach().long().to(device)\n",
    "\n",
    "        trn_output = mobile_net(trn_x)\n",
    "        loss = criterion(trn_output, trn_label)\n",
    "        train_loss += loss.item()\n",
    "        model_label = trn_output.argmax(dim=1)\n",
    "        corr = trn_label[trn_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += trn_label.size(0)\n",
    "    print(\"train_acc: {:.2f}%, train_loss: {:.4f}\".format(corr_num / total_num * 100, train_loss / len(trainloader)))\n",
    "\n",
    "\n",
    "# test acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    val_loss = 0.0\n",
    "    for j, val in enumerate(testloader):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label = val_label.clone().detach().long().to(device)\n",
    "\n",
    "        val_output = mobile_net(val_x)\n",
    "        loss = criterion(val_output, val_label)\n",
    "        val_loss += loss.item()\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "        accuracy = corr_num / total_num * 100\n",
    "        test_loss = val_loss / len(testloader)\n",
    "    print(\"test_acc: {:.2f}%, test_loss: {:.4f}\".format( accuracy, test_loss))\n",
    "\n",
    "# acc of each acc    \n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        x, labels = data\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = mobile_net(x)\n",
    "        labels = labels.long()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "PATH = './cifar10_fd_mobile.pth'#save trained model\n",
    "torch.save(mobile_net.state_dict(), PATH)\n",
    "\n",
    "end_time = time.time()  # store end time\n",
    "print(\"WorkingTime: {:.2f} sec\".format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('raspi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "18130e8b7df255a9e4715922ef5562126427c2cf5dea9fae05bc55150766c44c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
